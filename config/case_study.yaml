papers:
  transformers:
    arxiv_id: "1706.03762"
    title: "Attention Is All You Need"
    published_date: "2017-06-12"
    official_code: "https://github.com/tensorflow/tensor2tensor"
    authors:
      - "Vaswani"
      - "Shazeer"
      - "Parmar"
      - "Uszkoreit"
      - "Jones"
      - "Gomez"
      - "Kaiser"
      - "Polosukhin"

  capsules:
    arxiv_id: "1710.09829"
    title: "Dynamic Routing Between Capsules"
    published_date: "2017-10-26"
    official_code: null
    authors:
      - "Sabour"
      - "Frosst"
      - "Hinton"

api:
  semantic_scholar:
    base_url: "https://api.semanticscholar.org/graph/v1"
    rate_limit: 100  # per minute
    requests_per_second: 1.5

  github:
    rate_limit: 5000  # per hour
    # Will use GITHUB_TOKEN env var if available

  arxiv:
    max_results: 10
    retry_attempts: 3

collection:
  github:
    min_stars: 10
    min_forks: 5
    max_results_per_query: 100
    search_queries:
      transformers:
        - "attention is all you need"
        - "transformer attention mechanism"
        - "vaswani transformer"
        - "self-attention implementation"
      capsules:
        - "capsule networks"
        - "dynamic routing capsules"
        - "hinton capsules"
        - "capsnet"

  citations:
    start_year: 2017
    end_year: 2025

  boundary_objects:
    transformers:
      official_repos:
        - "tensorflow/tensor2tensor"
      early_commit_date: "2017-06-12"
    capsules:
      community_repos:
        - "naturomics/CapsNet-Tensorflow"
        - "XifengGuo/CapsNet-Keras"

database:
  collection_name: "case_study_papers"
  edge_collection_name: "case_study_citations"

logging:
  level: "INFO"
  file: "logs/case_study_collection.log"
